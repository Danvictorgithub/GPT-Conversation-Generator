# LLM Provider Configuration
LLM_PROVIDER=lmstudio
LLM_BASE_URL=http://localhost:1234/v1
LLM_API_KEY=sk-no-key-required
MODEL_NAME=deepseek-coder-v2-lite-instruct # Or use GPT

# LLM Generation Settings
MAX_TOKENS=1000
TEMPERATURE=0.7
REQUEST_TIMEOUT=120

# Server Configuration
INACTIVITY_TIMEOUT_MINUTE=3
SERVER_START_DELAY=2

# Database Configuration
DATABASE_URL=postgresql://postgres:your_password_here@localhost:5432/conversation-generator

# Flask Configuration
FLASK_ENV=production
FLASK_DEBUG=0
